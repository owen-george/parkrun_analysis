# Parkrun Analysis

## Overview
This project is designed to scrape, clean, and analyze data from parkrun events. It processes historical and real-time parkrun data to extract meaningful insights, such as personal bests, trends over time, and comparison of runners' performance across events.

## Features
- Scrapes data from parkrun events
- Cleans and filters data to ensure accuracy
- Computes personal bests (PB) and average run times
- Tracks runners' performance over time
- Calculates various metrics (e.g., position score, previous run performance)
- Visualizes the data with charts and graphs

## Technologies Used
- Python
- pandas
- numpy
- matplotlib
- Jupyter Notebooks

## Getting Started

### Prerequisites
- Python 3.x
- Anaconda or a virtual environment
- pandas, numpy, matplotlib

### Installation
1. Clone this repository:
git clone https://github.com/owen-george/parkrun_analysis.git


2. Navigate to the project directory:
cd parkrun_analysis


### Usage
1. Open Jupyter notebooks
2. Run the provided notebooks to load, clean, analyze, and visualize parkrun data.

## File Structure
- `data/` - Folder containing raw and processed parkrun data files.
- `functions/` - Python scripts for data cleaning and analysis.
- `figures/` - Folder containing visualizations generated from the analysis.
- `.gitignore` - Specifies files and directories to ignore in version control (e.g., `.ipynb_checkpoints`).
- `README.md` - This file.
